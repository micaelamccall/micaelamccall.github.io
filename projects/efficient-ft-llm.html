<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />


  <title>Micaela's Portfolio - Efficient Fine-tuning and Inference of LLMs for Question Answering</title>


  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="referrer" content="origin" />
  <meta name="generator" content="Pelican" />
<link href="/projects/efficient-ft-llm" rel="canonical" />
  <!-- Feed -->

  <link href="/theme/css/style.css" type="text/css" rel="stylesheet" />

  <!-- Code highlight color scheme -->
      <link href="/theme/css/code_blocks/github.css" rel="stylesheet">


  <!-- So that plotly will work -->
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <script src="//cdnjs.cloudflare.com/ajax/libs/require.js/2.3.5/require.min.js"></script>
  
  <!-- Custom fonts -->
  <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
  <link href='https://fonts.googleapis.com/css?family=Montserrat:400,300' rel='stylesheet' type='text/css' />
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css" />

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->



    <meta name="description" content="Python, Large Language Models, Transformers, Parameter-Efficient Fine-Tuning, Prompt-Tuning, Adapters">

    <meta name="author" content="micaelavmccall">





<!-- Open Graph -->
<meta property="og:site_name" content="Micaela's Portfolio"/>
<meta property="og:title" content="Efficient Fine-tuning and Inference of LLMs for Question Answering"/>
<meta property="og:description" content="Python, Large Language Models, Transformers, Parameter-Efficient Fine-Tuning, Prompt-Tuning, Adapters"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="/projects/efficient-ft-llm"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2024-06-01 00:00:00-04:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="/author/micaelavmccall.html">
<meta property="article:section" content="Projects"/>
<meta property="og:image" content="/theme/images/post-bg.jpg">

<!-- Twitter Card -->

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "name": "Efficient Fine-tuning and Inference of LLMs for Question Answering",
  "headline": "Efficient Fine-tuning and Inference of LLMs for Question Answering",
  "datePublished": "2024-06-01 00:00:00-04:00",
  "dateModified": "",
  "author": {
    "@type": "Person",
    "name": "micaelavmccall",
    "url": "/author/micaelavmccall.html"
  },
  "image": "/theme/images/post-bg.jpg",
  "url": "/projects/efficient-ft-llm",
  "description": "Python, Large Language Models, Transformers, Parameter-Efficient Fine-Tuning, Prompt-Tuning, Adapters"
}
</script>
</head>
<!-- TODO : Body class -->
<body class="home-template">

<nav id="menu">
  <a class="close-button">Close</a>
  <div class="nav-wrapper">
    <p class="nav-label">Menu</p>
    <ul>

              <li role="presentation"><a href="/">Home</a></li>
              <li role="presentation"><a href="/about">About</a></li>
              <li class="nav-projects active" role="presentation"><a href="/projects">Projects</a></li>

    </ul>
  </div>
</nav>
    <!-- Progressbar -->
    <div class="progress-container">
        <span class="progress-bar"></span>
    </div>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header id="post-header" >
      <div class="inner">
        <nav id="navigation">
            <span id="home-button" class="nav-button">
                <a class="home-button" href="/" title="Home"> Micaela McCall</a>
            </span>
          <span id="menu-button" class="nav-button">
            <a class="menu-button"><i class="ic ic-menu"></i> Menu</a>
          </span>
        </nav>
        <h1 class="post-title">Efficient Fine-tuning and Inference of LLMs for Question Answering</h1>
        <!-- TODO : Proper class for headline -->
        <!--             <span class="blog-description">Python, Large Language Models, Transformers, Parameter-Efficient Fine-Tuning, Prompt-Tuning, Adapters</span>
 -->
        <span class="post-meta">
              <span>Python, Large Language Models, Transformers, Parameter-Efficient Fine-Tuning, Prompt-Tuning, Adapters</span>
            <!--                 <a href="/author/micaelavmccall.html">Micaela McCall</a>
            | <time datetime="Sat 01 June 2024">Sat 01 June 2024</time> -->
        </span>
        <!-- TODO : Modified check -->
      </div>
    </header>

  <section id="wrapper">
    <a class="hidden-close"></a>

    <!-- Post content -->
    <main class="content" role="main">
        <article class="post">
        <div class="inner">
            <section class="post-content">
                <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css"> .highlight pre  .hll { background-color: #ffffcc }
 .highlight pre   { background: #f8f8f8; }
 .highlight pre  .c { color: #408080; font-style: italic } /* Comment */
 .highlight pre  .err { border: 1px solid #FF0000 } /* Error */
 .highlight pre  .k { color: #008000; font-weight: bold } /* Keyword */
 .highlight pre  .o { color: #666666 } /* Operator */
 .highlight pre  .ch { color: #408080; font-style: italic } /* Comment.Hashbang */
 .highlight pre  .cm { color: #408080; font-style: italic } /* Comment.Multiline */
 .highlight pre  .cp { color: #BC7A00 } /* Comment.Preproc */
 .highlight pre  .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */
 .highlight pre  .c1 { color: #408080; font-style: italic } /* Comment.Single */
 .highlight pre  .cs { color: #408080; font-style: italic } /* Comment.Special */
 .highlight pre  .gd { color: #A00000 } /* Generic.Deleted */
 .highlight pre  .ge { font-style: italic } /* Generic.Emph */
 .highlight pre  .gr { color: #FF0000 } /* Generic.Error */
 .highlight pre  .gh { color: #000080; font-weight: bold } /* Generic.Heading */
 .highlight pre  .gi { color: #00A000 } /* Generic.Inserted */
 .highlight pre  .go { color: #888888 } /* Generic.Output */
 .highlight pre  .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
 .highlight pre  .gs { font-weight: bold } /* Generic.Strong */
 .highlight pre  .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
 .highlight pre  .gt { color: #0044DD } /* Generic.Traceback */
 .highlight pre  .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
 .highlight pre  .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
 .highlight pre  .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
 .highlight pre  .kp { color: #008000 } /* Keyword.Pseudo */
 .highlight pre  .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
 .highlight pre  .kt { color: #B00040 } /* Keyword.Type */
 .highlight pre  .m { color: #666666 } /* Literal.Number */
 .highlight pre  .s { color: #BA2121 } /* Literal.String */
 .highlight pre  .na { color: #7D9029 } /* Name.Attribute */
 .highlight pre  .nb { color: #008000 } /* Name.Builtin */
 .highlight pre  .nc { color: #0000FF; font-weight: bold } /* Name.Class */
 .highlight pre  .no { color: #880000 } /* Name.Constant */
 .highlight pre  .nd { color: #AA22FF } /* Name.Decorator */
 .highlight pre  .ni { color: #999999; font-weight: bold } /* Name.Entity */
 .highlight pre  .ne { color: #D2413A; font-weight: bold } /* Name.Exception */
 .highlight pre  .nf { color: #0000FF } /* Name.Function */
 .highlight pre  .nl { color: #A0A000 } /* Name.Label */
 .highlight pre  .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
 .highlight pre  .nt { color: #008000; font-weight: bold } /* Name.Tag */
 .highlight pre  .nv { color: #19177C } /* Name.Variable */
 .highlight pre  .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
 .highlight pre  .w { color: #bbbbbb } /* Text.Whitespace */
 .highlight pre  .mb { color: #666666 } /* Literal.Number.Bin */
 .highlight pre  .mf { color: #666666 } /* Literal.Number.Float */
 .highlight pre  .mh { color: #666666 } /* Literal.Number.Hex */
 .highlight pre  .mi { color: #666666 } /* Literal.Number.Integer */
 .highlight pre  .mo { color: #666666 } /* Literal.Number.Oct */
 .highlight pre  .sa { color: #BA2121 } /* Literal.String.Affix */
 .highlight pre  .sb { color: #BA2121 } /* Literal.String.Backtick */
 .highlight pre  .sc { color: #BA2121 } /* Literal.String.Char */
 .highlight pre  .dl { color: #BA2121 } /* Literal.String.Delimiter */
 .highlight pre  .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
 .highlight pre  .s2 { color: #BA2121 } /* Literal.String.Double */
 .highlight pre  .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */
 .highlight pre  .sh { color: #BA2121 } /* Literal.String.Heredoc */
 .highlight pre  .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */
 .highlight pre  .sx { color: #008000 } /* Literal.String.Other */
 .highlight pre  .sr { color: #BB6688 } /* Literal.String.Regex */
 .highlight pre  .s1 { color: #BA2121 } /* Literal.String.Single */
 .highlight pre  .ss { color: #19177C } /* Literal.String.Symbol */
 .highlight pre  .bp { color: #008000 } /* Name.Builtin.Pseudo */
 .highlight pre  .fm { color: #0000FF } /* Name.Function.Magic */
 .highlight pre  .vc { color: #19177C } /* Name.Variable.Class */
 .highlight pre  .vg { color: #19177C } /* Name.Variable.Global */
 .highlight pre  .vi { color: #19177C } /* Name.Variable.Instance */
 .highlight pre  .vm { color: #19177C } /* Name.Variable.Magic */
 .highlight pre  .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h3 id="Advancing-Question-Answering-with-Decoder-Only-Causal-Language-Models:-Efficient-Fine-Tuning-and-Inference-Techniques-for-Large-Scale-QA">Advancing Question Answering with Decoder-Only Causal Language Models: Efficient Fine-Tuning and Inference Techniques for Large-Scale QA<a class="anchor-link" href="#Advancing-Question-Answering-with-Decoder-Only-Causal-Language-Models:-Efficient-Fine-Tuning-and-Inference-Techniques-for-Large-Scale-QA">&#182;</a></h3><p>This was a group project completed for GA Tech's CS 7643: Deep Learning. My group mates were Andrey Shor (<a href="https://www.linkedin.com/in/andrey-shor/">LinkedIn</a>) and Artem Maryanskyy (<a href="a.maryanskyy@gatech.edu">Email</a>).</p>
<p>Large language models (LLMs), large-scale deep learning models using a transformer architecture, are the current state-of-the-art for processing and understanding written language. Trained on massive amounts of text-based data, these models can be used to perform a number of natural language processing (NLP) tasks, such as text generation, summarization of long texts, and translation [1]. Because these models are so versatile, it has become customary to pre-train LLMs on general, task-agnostic data and publish them for the use of multiple downstream tasks.</p>
<p><img src="../images/decoder.jpeg" alt=""></p>
<p>Many approaches are effective at adapting pre-trained LLMs for a specific task. This process, called fine-tuning, can be very computationally heavy when performed as a standard training process, i.e., requiring the updating of billions of model parameters. Therefore, much contemporary LLM research focuses on increasing efficiency of the fine-tuning process. One very fruitful type of approach is Parameter Efficient Fine Tuning Methods (PEFT), which improve efficiency by reducing the number of model parameters that must be updated during gradient-descent-based fine-tuning, and thereby reduce requisite memory and computation [2].</p>
<p>Another approach to increasing LLM efficiency is to focus on inference time. One exmaple of this is In-Context Learning (ICL) methods, which bypass gradient-descent-based fine-tuning entirely by leveraging the emergent property of LLMs that they are able to perform on previously unseen tasks after seeing some examples of that task [3]. Depending on how many (training) examples of the new task are fed to the model, the approach may be referred to as Zero-Shot, One-Shot, or Few-Shot ICL.</p>
<p>These are only a couple broad categories of approaches in a field that is teeming with fresh ideas and combinations of existing ideas. Given this abundance, there is a need for thorough and specific direct comparisons in order to discover the optimal combination of methods for the task-specific adaptation of pre-trained LLMs.</p>
<p><img src="../images/peft_diagram.jpg" alt=""></p>
<h3 id="Project-Goals">Project Goals<a class="anchor-link" href="#Project-Goals">&#182;</a></h3><p>In this project, we employed a selection of efficiency approaches to fine-tune each of three publicly available pre-trained LLMs. By comparing the inference speed of each method and the performance of the resultant fine-tuned models, we aimed to contribute to the search for optimal fine-tuning approaches.</p>
<h3 id="Models-and-Data-Sources">Models and Data Sources<a class="anchor-link" href="#Models-and-Data-Sources">&#182;</a></h3><p>The pre-trained models are all available on HuggingFace: the <a href="https://huggingface.co/meta-llama/Llama-2-7b">7 Billion parameter version of Llama</a>,  <a href="https://huggingface.co/google/gemma-2b">the 2 Billion parameter version of Gemma</a>, <a href="https://huggingface.co/google/gemma-7b">the 7 Billion parameter version of Gemma</a>, and <a href="https://huggingface.co/mistralai/Mistral-7B-v0.1">the 7 Billion parameter version of Mistral</a>. All three models are pre-trained generative LLMs that use a decoder-only transformer architecture.</p>
<p>All fine-tuning experiments were done using the UnifiedQA dataset, which consistis of a collection of different question-answering datasets that span four formats: yes/no, multiple choice, extractive (the question is a paragraph and the answer is a substring from the paragraph), and abstractive (the question is a paragraph and the answer is something about that paragraph but is more than just a substring) [4].</p>
<p>A note on using decoder-only transformers for question-answering tasks: compared to a encoder-decoder architecture, in which a model explicitly learns about the dependencies between tokens in the question, via the encoder, in order to produce answers, via the decoder, decoder-only architectures generate text simply as next-word prediction (attending only to positions prior to that of the current token) [5]. Despite this, decoder-only LLMs display impressive emergent properties that allow them to be applied to many types of tasks out-of-the-box, and with fine-tuning can learn to answer questions in the format desired [5].</p>
<h3 id="Efficient-Fine-Tuning-and-Inference-Details">Efficient Fine-Tuning and Inference Details<a class="anchor-link" href="#Efficient-Fine-Tuning-and-Inference-Details">&#182;</a></h3><p><strong>Parameter Efficient Fine-Tuning (PEFT)</strong></p>
<ul>
<li>Low Rank Adaptation (LoRA) introduces trainable decomposition matrices into the model and effectively performs low-rank decomposition on model parameter matrices while preserving essential information [6]. </li>
<li>Quantization LoRA (QLoRA) additionally quantizes the weights of the pre-trained network, meaning it converts weights from high-precision data types to low-precision data types (such as from float-32 to int-8), which compresses the model [6]. </li>
<li>Adaptive LorRA (AdaLoRA) adaptively assigns more or fewer rank (more or fewer parameters) to matrices with more or less importance, (addressing a LoRA shortcoming of assuming a constant importance of each weight matrix across layers by pre-specifying the rank of the decomposition matrix [7]).</li>
</ul>
<p><strong>Adapter-based Tuning</strong> takes the approach of adding adapter modules (new, randomly-initialized layers) to the transformer-based architecture and updating the adapter weights while keeping the pre-trained weights frozen [8].</p>
<ul>
<li>Infused Adapter by Inhibiting and Amplifying Inner Activations (IA)3,  introduces a set of learned vectors to rescale the model’s activations, namely the keys and values in attention layers and inner products of feedforward layers [9].</li>
</ul>
<p><strong>Prompt-tuning</strong> reduces trainable parameters by adding discrete (or manually written) prompt tokens to the input and performing fine-tuning by updating the parameters associated with those prompts [10].</p>
<p><strong>Speculative Decoding</strong> speeds up sampling from LLMs by computing tokens in parallel using several smaller, approximation models that create a number of guesses at prefixes which are then evaluated by the larger model and chosen if they don’t change the target distribution [11].</p>
<h3 id="Hardware-Requirements">Hardware Requirements<a class="anchor-link" href="#Hardware-Requirements">&#182;</a></h3><p>We used Lambdalabs [12], which is a GPU-as-a-service provider that rents out GPUs, to perform many of the above fine-tuning methods as well as inference. In order to do so, we developed a PEFT Training CLI, uploaded it to Lambdalabs, and implemented four bash scripts to run it. The four experiments we ran with these bash scripts were QLoRA, Quantized Adalora, Quantized IA3, and Quantized Prompt Tuning. We had to run the models in quantized versions as the hardware requirements we utilized (1 x A100 GPU on Lambda Labs) did not have enough memory to be able to handle the unquantized variants during training.</p>
<p>We used the same A100 GPU instance for inference with the fine-tuned PEFT models, as well as for ICL and speculative decoding.</p>
<h3 id="Summary-of-Findings">Summary of Findings<a class="anchor-link" href="#Summary-of-Findings">&#182;</a></h3><p>We implemented each PEFT, ICL, and inference-time efficiency method described above and evaluated each one by measuring the performance of the resultant models on test data and the inference-time efficiency while generating predictions.</p>
<p>We evaluated each approach using accuracy (Jaccard similarity), perplexity (which captures the degree of uncertainty of the model when seeing new data), and GPU throughput (number of output tokens the model generates per second).</p>
<p><strong>Gemma 2B Results</strong>
|  Approach |  Test Accuracy |Test Avg Jaccard Similarity| GPU Throughput | Training Perplexity |
|  ---------| ---------------| -----------------------| --------------| ---------------|
|  QLoRA    |     0.0        |   0.1878             |       169.6         |    24.6407       | 
|  AdaLoRA  |     0.0        |   0.2133             |    135.0            |   638.3585       |
|  (IA)^3   |     0.0        |   0.2125             |    180.3            |    35.6803       |
|  Prompt Tuning  |     0.0  |   0.0449             |    190.5            |    35.6803       |</p>
<p><strong>Gemma 7B Results</strong>
|  Approach |  Test Accuracy |Test Avg Jaccard Similarity| GPU Throughput | Training Perplexity |
|  ---------| ---------------| -----------------------| --------------| ---------------|
|  QLoRA    |     0.0        |   0.1878             |       169.6         |    24.6407       | 
|  AdaLoRA  |     0.0        |   0.2133             |    135.0            |   638.3585       |
|  (IA)^3   |     0.0        |   0.2125             |    180.3            |    35.6803       |
|  Prompt Tuning  |     0.0  |   0.0449             |    190.5            |    35.6803       |</p>
<p><strong>Llama 7B Results</strong>
|  Approach |  Test Accuracy |Test Avg Jaccard Similarity| GPU Throughput | Training Perplexity |
|  ---------| ---------------| -----------------------| --------------| ---------------|
|  QLoRA    |     0.0        |   0.1878             |       169.6         |    24.6407       | 
|  AdaLoRA  |     0.0        |   0.2133             |    135.0            |   638.3585       |
|  (IA)^3   |     0.0        |   0.2125             |    180.3            |    35.6803       |
|  Prompt Tuning  |     0.0  |   0.0449             |    190.5            |    35.6803       |</p>
<p><strong>Mistral 7B Results</strong>
|  Approach |  Test Accuracy |Test Avg Jaccard Similarity| GPU Throughput | Training Perplexity |
|  ---------| ---------------| -----------------------| --------------| ---------------|
|  QLoRA    |     0.0        |   0.1878             |       169.6         |    24.6407       | 
|  AdaLoRA  |     0.0        |   0.2133             |    135.0            |   638.3585       |
|  (IA)^3   |     0.0        |   0.2125             |    180.3            |    35.6803       |
|  Prompt Tuning  |     0.0  |   0.0449             |    190.5            |    35.6803       |</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<hr>
<h2 id="Full-Project">Full Project<a class="anchor-link" href="#Full-Project">&#182;</a></h2><h3 id="Data-Preprocessing">Data Preprocessing<a class="anchor-link" href="#Data-Preprocessing">&#182;</a></h3><p>The raw UnifiedQA datasets were downloaded from Google storage using a script provided by Allen AI [4]. Basic preprocessing was performed to generate lowercase text .json files with ‘id’, ‘question’, and ‘answer’ keys containing lists for each data sample. Each of the three models expect a different QA format; however, these idiosyncracies are not something that is widely documented. See the links in the code below for where the method was found.</p>
<!-- |  Model    |  Question Tag  |   Answer Tag   |    Other Tags | Resource |
|  ---------| ---------------| ---------------| --------------| ---------|
|  Gemma    | Prepend `<start_of_turn>user\n` and append `<end_of_turn>\n\n`|  Prepend `<start_of_turn>model\n` and append `<end_of_turn>` |   Prepend `<bos>` to question | [Link](https://huggingface.co/google/gemma-7b/discussions/62)|
|  Llama    |  Prepend `Input:\n`|   Prepend `Output:\n`|    Prepend `<s>` to question | [Link1](https://huggingface.co/docs/optimum-neuron/en/tutorials/fine_tune_llama_7b), [Link2](https://github.com/mallorbc/llama_dataset_formats/blob/26b29649dca39552e2ecb9d7041468488b9b0f32/README.md)|
|  Mistral  |  Prepend `[INST] ` and append  ` [/INST]` |   N/A|    Prepend `<s>` to question | [Link](https://www.promptingguide.ai/models/mistral-7b)| -->


<p>Finally, the model-specific datasets were tokenized using a HuggingFace- developed procedure that uses the pre-trained tokenizer associated with a pre-trained model hosted on HuggingFace (as were all the models we used).</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">json</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="k">import</span> <span class="n">tqdm</span>
<span class="c1"># HuggingFace packages: </span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">AutoTokenizer</span> 
<span class="kn">from</span> <span class="nn">datasets</span> <span class="k">import</span> <span class="n">Dataset</span>


<span class="k">def</span> <span class="nf">make_unified_qa_dataset</span><span class="p">(</span><span class="n">unified_datasets</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">data_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">data_type</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Func to generate .json dataset with &quot;id&quot;, &quot;question&quot;, and &quot;answer&quot; keys. &quot;id&quot; is created for each dataset specifically</span>
<span class="sd">    Args:</span>
<span class="sd">        unified_datasets: a list of names of datasets within the unified datasets list</span>
<span class="sd">            e.g. UNIFIED_DATASETS = [&quot;narrativeqa&quot;,</span>
<span class="sd">                                    &quot;ai2_science_middle&quot;, &quot;ai2_science_elementary&quot;,</span>
<span class="sd">                                    &quot;arc_hard&quot;, &quot;arc_easy&quot;,</span>
<span class="sd">                                    &quot;mctest_corrected_the_separator&quot;,</span>
<span class="sd">                                    &quot;squad1_1&quot;, &quot;squad2&quot;,&quot;boolq&quot;,</span>
<span class="sd">                                    &quot;race_string&quot;,&quot;openbookqa&quot;]</span>
<span class="sd">        data_path: local path to store json</span>
<span class="sd">        data_type: which section of dataset to process; &quot;train&quot;, &quot;dev&quot;, or &quot;test&quot; </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">data_type</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;dev&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span> <span class="s2">&quot;data_type must be &#39;train&#39;, &#39;dev&#39;, or &#39;test&#39;&quot;</span>
    <span class="n">unified_dataset</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">unified_datasets</span><span class="p">:</span>
        <span class="n">curr_data_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_path</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">f</span><span class="s2">&quot;</span><span class="si">{data_type}</span><span class="s2">.tsv&quot;</span><span class="p">)</span>
        <span class="n">unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">curr_data_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf-8&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">cnt</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">f</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">():</span>  
                    <span class="n">question</span><span class="p">,</span> <span class="n">answer</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s2">&quot;id&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;</span><span class="si">{dataset}</span><span class="s2">-</span><span class="si">{data_type}</span><span class="s2">-</span><span class="si">{cnt}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="n">unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s2">&quot;question&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">question</span><span class="p">)</span>
                    <span class="n">unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">answer</span><span class="p">)</span>
                    <span class="n">cnt</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">unified_dataset</span>


<span class="k">def</span> <span class="nf">preprocess_unified_qa_dataset</span><span class="p">(</span><span class="n">datasets</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">append_instruction_gemma</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">append_instruction_llama</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                                  <span class="n">append_instruction_mistral</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">append_bos</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">append_s</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Func to process data into its model-specific format; must create a version for each model bc</span>
<span class="sd">    each model expects a different chat structure&#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">sum</span><span class="p">([</span><span class="n">append_instruction_gemma</span><span class="p">,</span> <span class="n">append_instruction_llama</span><span class="p">,</span> <span class="n">append_instruction_mistral</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
    <span class="s2">&quot;Exactly one &#39;append_instruction...&#39; parameter must be true&quot;</span>
    <span class="k">assert</span> <span class="nb">sum</span><span class="p">([</span><span class="n">append_bos</span><span class="p">,</span> <span class="n">append_s</span><span class="p">])</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">,</span> \
    <span class="s2">&quot;At most one of &#39;append_bos&#39; or &#39;append_s&#39; can be true&quot;</span>

    <span class="n">preprocessed_unified_dataset</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">datasets</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;id&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;question&quot;</span><span class="p">:</span> <span class="p">[],</span> <span class="s2">&quot;answer&quot;</span><span class="p">:</span> <span class="p">[]}</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">id</span> <span class="k">for</span> <span class="nb">id</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;id&#39;</span><span class="p">]]</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">question</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">answer</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">datasets</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">append_instruction_gemma</span><span class="p">:</span> <span class="c1"># For Gemma Models: https://huggingface.co/google/gemma-7b/discussions/62</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;start_of_turn&gt;user</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">question</span> <span class="o">+</span> <span class="s2">&quot;&lt;end_of_turn&gt;</span><span class="se">\n\n</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;start_of_turn&gt;model</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">answer</span> <span class="o">+</span> <span class="s2">&quot;&lt;end_of_turn&gt;&quot;</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">append_instruction_llama</span><span class="p">:</span> <span class="c1"># For Llama 2: https://huggingface.co/docs/optimum-neuron/en/tutorials/fine_tune_llama_7b or https://github.com/mallorbc/llama_dataset_formats/blob/26b29649dca39552e2ecb9d7041468488b9b0f32/README.md</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Input:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">question</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Output:</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="n">answer</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">append_instruction_mistral</span><span class="p">:</span> <span class="c1"># For Mistral 7b: https://www.promptingguide.ai/models/mistral-7b</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;[INST] &quot;</span> <span class="o">+</span> <span class="n">question</span> <span class="o">+</span> <span class="s2">&quot; [/INST]&quot;</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span> 
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">answer</span> <span class="k">for</span> <span class="n">answer</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;answer&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">append_bos</span><span class="p">:</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;bos&gt;&quot;</span><span class="o">+</span><span class="n">question</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span>
        <span class="k">if</span> <span class="n">append_s</span><span class="p">:</span>
            <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;s&gt;&quot;</span><span class="o">+</span><span class="n">question</span> <span class="o">+</span> <span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span> <span class="k">for</span> <span class="n">question</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;question&#39;</span><span class="p">]]</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">q</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">a</span> <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s2">&quot;question&quot;</span><span class="p">],</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s2">&quot;answer&quot;</span><span class="p">])]</span>
    <span class="k">return</span> <span class="n">preprocessed_unified_dataset</span>


<span class="k">def</span> <span class="nf">tokenize_dataset</span><span class="p">(</span><span class="n">preprocessed_unified_dataset</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">pad_token</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">pad_side</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Func to tokenize the processed dataset using a pretrained HuggingFace tokenizer</span>
<span class="sd">    Args:</span>
<span class="sd">        preprocessed_unified_dataset: output from &quot;preprocess_unified_qa_dataset&quot;</span>
<span class="sd">        model_name: one of &quot;google/gemma-7b&quot;, &quot;mistralai/Mistral-7B-v0.1&quot;, &quot;meta-llama/Llama-2-7b-hf&quot;</span>
<span class="sd">        pad_token: Whether to pad with EOS token</span>
<span class="sd">        pad_sice: which side to pad with pad token</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pad_token</span><span class="p">:</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
        <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="n">pad_side</span>
    <span class="k">for</span> <span class="n">dataset</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">item</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s1">&#39;pt&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">preprocessed_unified_dataset</span><span class="p">[</span><span class="n">dataset</span><span class="p">][</span><span class="s1">&#39;text&#39;</span><span class="p">]]</span>
    <span class="k">return</span> <span class="n">preprocessed_unified_dataset</span>


<span class="k">def</span> <span class="nf">load_tokenized_dataset</span><span class="p">(</span><span class="n">file_path</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;From a given local file path, create a HuggingFace Dataset object from a .json file with</span>
<span class="sd">    &quot;id&quot;, &quot;questions&quot;, &quot;answers&quot;, &quot;text&quot; and &quot;input_ids&quot; keys&#39;&#39;&#39;</span>
    <span class="n">data_dict</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
        <span class="nb">id</span><span class="p">,</span> <span class="n">questions</span><span class="p">,</span> <span class="n">answers</span><span class="p">,</span> <span class="n">text</span><span class="p">,</span> <span class="n">input_id</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

        <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">id</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;questions&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">questions</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;answers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">answers</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">text</span>
        <span class="n">data_dict</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">input_id</span>

    <span class="k">return</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">data_dict</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<!-- ## Quantization Experiments 

As described above, quantization means compressing the model by converting the datatypes of the weights from higher-precision to lower-precision datatypes. It can be done in tandem with a LoRA or another PEFT technique, or on it's own to reduce the compute and memory required to use a model after training. When used in this latter way, it is similar to an inference-efficiency technique. Because we were dealing with resource constraints in terms of the GPU available to us, we performed a variety of quantization experiements  -->
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Efficient-Fine-Tuning">Efficient Fine-Tuning<a class="anchor-link" href="#Efficient-Fine-Tuning">&#182;</a></h2><p>Each efficiency method that involves further training and/or modification of the base model in some way was performed on a Lambdalabs instance. Experiments were implemented via a Python CLI tool that performed the folliowng steps:</p>
<ul>
<li>Load the specified model  (Gemma-2b, Gemma-7b, Llama-7b, and Mistral-7b) and corresponding tokenizer from HuggingFace. </li>
<li>Load a configuration for the specified PEFT approach, which specifies required parameters and hyperparameters that vary from approach to approach. </li>
<li>Train the model using the PEFT hyperparameters and the general training hyperparameters mentioned below. </li>
<li>When training is complete, save the trained model and the training losses.</li>
</ul>
<p>Below is a description of each approach-specific hyperparameter: 
|  Approach |  Hyperparameter  | Description |
|  ---------| -----------------| ------------|
|  LoRA, QLoRa, AdaLoRA  | r |  Rank; the size of the low-rank matrices used to decompose the weight ma- trix. |
|      |  alpha|  Scaling factor applied to the learned decomposition matrices.|
|      |  bias|  Whether “none”, “all”, or only the LoRA bias parameters should be trained.|
|      |  dropout|  The dropout probability for LoRA layers.|
|  AdaLoRA  | target_r |  The target average rank of incremental matrix. |
|      | init_r | The initial rank for each incremental matrix. |
|      | tinit | The steps of initial fine-tuning warmup. |
|      | tfinal | The step of final fine-tuning. |
|  QLoRA Quantization  | load_in_4bit |  Whether to quantize the model to 4-bits when you load it set [14]. |
|     | bnb_4bit_compute_dtype |  The computational type which might be different than the input time. Use torch.bfloat16 for speedups [14]. |
|     | bnb_4bit_use_double_quant |  Whether to use a nested quantization scheme to quantize the already quan- tized weights set [14]. |
|  (IA)^3  | target_modules | The layers to apply rescaling to [9,15]. |
|  Prompt Tuning | prompt_tuning_init | The initialization of the prompt embedding [4]. |
|     | prompt_tuning_init_text | The text to initialize the prompt embedding [4]. |
|     | prompt_tuning_init_text | The text to initialize the prompt embedding [4]. |</p>
<p>While I didn't include the CLI in this notebook, below are a number of functions used to load the models, training configs, and to call the training procedures.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="c1"># HuggingFace packages: </span>
<span class="kn">from</span> <span class="nn">datasets</span> <span class="k">import</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">peft</span> <span class="k">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">PeftModel</span><span class="p">,</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">,</span> <span class="n">IA3Config</span><span class="p">,</span> <span class="n">AdaLoraConfig</span><span class="p">,</span> <span class="n">PromptTuningConfig</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">pipeline</span>
<span class="kn">from</span> <span class="nn">trl</span> <span class="k">import</span> <span class="n">SFTTrainer</span>

<span class="c1"># for lora and qlora: https://www.databricks.com/blog/efficient-fine-tuning-lora-guide-llms</span>
<span class="k">def</span> <span class="nf">prepare_lora_config</span><span class="p">(</span><span class="n">r</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">lora_alpha</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">lora_dropout</span><span class="p">:</span><span class="nb">float</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> 
                        <span class="n">targets</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">task_type</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;CAUSAL_LM&#39;</span><span class="p">):</span> <span class="c1"># can also take attn</span>
    <span class="k">assert</span> <span class="n">targets</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;attn&#39;</span><span class="p">],</span> <span class="s2">&quot;Targets must be &#39;linear&#39; or &#39;attn&#39;.&quot;</span>
    <span class="k">if</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>  <span class="c1"># per literature review, best performance is when LoRA and QLoRA are applied to lora linear layers</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;q_proj&#39;</span><span class="p">,</span><span class="s1">&#39;k_proj&#39;</span><span class="p">,</span><span class="s1">&#39;v_proj&#39;</span><span class="p">,</span><span class="s1">&#39;o_proj&#39;</span><span class="p">,</span><span class="s1">&#39;gate_proj&#39;</span><span class="p">,</span><span class="s1">&#39;down_proj&#39;</span><span class="p">,</span><span class="s1">&#39;up_proj&#39;</span><span class="p">,</span><span class="s1">&#39;lm_head&#39;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;attn&#39;</span><span class="p">:</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">LoraConfig</span><span class="p">(</span><span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span> <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span> 
                      <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="n">task_type</span><span class="p">)</span>

<span class="c1"># for IA3: https://huggingface.co/docs/peft/en/package_reference/ia3</span>
<span class="k">def</span> <span class="nf">prepare_ia3_config</span><span class="p">(</span><span class="n">r</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">targets</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">feedforward_modules</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
                       <span class="n">task_type</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;CAUSAL_LM&#39;</span><span class="p">):</span> <span class="c1"># can also take attn</span>
    <span class="k">assert</span> <span class="n">targets</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;attn&#39;</span><span class="p">],</span> <span class="s2">&quot;Targets must be &#39;linear&#39; or &#39;attn&#39;.&quot;</span>
    <span class="k">if</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;q_proj&#39;</span><span class="p">,</span><span class="s1">&#39;k_proj&#39;</span><span class="p">,</span><span class="s1">&#39;v_proj&#39;</span><span class="p">,</span><span class="s1">&#39;o_proj&#39;</span><span class="p">,</span><span class="s1">&#39;gate_proj&#39;</span><span class="p">,</span><span class="s1">&#39;down_proj&#39;</span><span class="p">,</span><span class="s1">&#39;up_proj&#39;</span><span class="p">,</span><span class="s1">&#39;lm_head&#39;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;attn&#39;</span><span class="p">:</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">IA3Config</span><span class="p">(</span><span class="n">peft_type</span><span class="o">=</span><span class="s2">&quot;IA3&quot;</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="n">task_type</span><span class="p">,</span> <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span> 
                     <span class="n">feedforward_modules</span><span class="o">=</span><span class="n">feedforward_modules</span><span class="p">)</span>

<span class="c1"># for AdaLora: https://huggingface.co/docs/peft/en/package_reference/adalora</span>
<span class="k">def</span> <span class="nf">prepare_adalora_config</span><span class="p">(</span><span class="n">r</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">lora_alpha</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">lora_dropout</span><span class="p">:</span><span class="nb">float</span><span class="o">=.</span><span class="mi">05</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="s1">&#39;none&#39;</span><span class="p">,</span> 
                           <span class="n">targets</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">task_type</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;CAUSAL_LM&#39;</span><span class="p">):</span> <span class="c1"># can also take attn</span>
    <span class="k">assert</span> <span class="n">targets</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;attn&#39;</span><span class="p">],</span> <span class="s2">&quot;Targets must be &#39;linear&#39; or &#39;attn&#39;.&quot;</span>
    <span class="k">if</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;linear&#39;</span><span class="p">:</span>  <span class="c1"># per literature review, best performance is when LoRA and QLoRA are applied to lora linear layers</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;q_proj&#39;</span><span class="p">,</span><span class="s1">&#39;k_proj&#39;</span><span class="p">,</span><span class="s1">&#39;v_proj&#39;</span><span class="p">,</span><span class="s1">&#39;o_proj&#39;</span><span class="p">,</span><span class="s1">&#39;gate_proj&#39;</span><span class="p">,</span><span class="s1">&#39;down_proj&#39;</span><span class="p">,</span><span class="s1">&#39;up_proj&#39;</span><span class="p">,</span><span class="s1">&#39;lm_head&#39;</span><span class="p">]</span>
    <span class="k">elif</span> <span class="n">targets</span> <span class="o">==</span> <span class="s1">&#39;attn&#39;</span><span class="p">:</span>
        <span class="n">target_modules</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;q_proj&quot;</span><span class="p">,</span> <span class="s2">&quot;v_proj&quot;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">AdaLoraConfig</span><span class="p">(</span><span class="n">peft_type</span><span class="o">=</span><span class="s2">&quot;ADALORA&quot;</span><span class="p">,</span> <span class="n">task_type</span><span class="o">=</span><span class="n">task_type</span><span class="p">,</span> <span class="n">r</span><span class="o">=</span><span class="n">r</span><span class="p">,</span> <span class="n">target_modules</span><span class="o">=</span><span class="n">target_modules</span><span class="p">,</span> 
                         <span class="n">lora_alpha</span><span class="o">=</span><span class="n">lora_alpha</span><span class="p">,</span> <span class="n">lora_dropout</span><span class="o">=</span><span class="n">lora_dropout</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>

<span class="c1"># https://huggingface.co/docs/peft/en/package_reference/prompt_tuning</span>
<span class="c1"># https://huggingface.co/docs/peft/main/en/task_guides/clm-prompt-tuning</span>
<span class="k">def</span> <span class="nf">prepare_prompt_tuning_config</span><span class="p">(</span><span class="n">task_type</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;CAUSAL_LM&#39;</span><span class="p">,</span> <span class="n">num_virtual_tokens</span><span class="p">:</span><span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> 
                                 <span class="n">prompt_tuning_init_task</span><span class="p">:</span><span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tokenizer_model</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">PromptTuningConfig</span><span class="p">(</span><span class="n">task_type</span><span class="o">=</span><span class="n">task_type</span><span class="p">,</span> <span class="n">prompt_tuning_init</span><span class="o">=</span><span class="s2">&quot;TEXT&quot;</span><span class="p">,</span> 
                              <span class="n">num_virtual_tokens</span><span class="o">=</span><span class="n">num_virtual_tokens</span><span class="p">,</span> <span class="n">prompt_tuning_init_text</span><span class="o">=</span><span class="n">prompt_tuning_init_task</span><span class="p">,</span>
                              <span class="n">tokenizer_name_or_path</span><span class="o">=</span><span class="n">tokenizer_model</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">prepare_peft_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">use_cache</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">PeftModel</span><span class="p">:</span> 
    <span class="sd">&#39;&#39;&#39;Creates a PeftModel HuggingFace object by wrapping a pretrained model in some functionality </span>
<span class="sd">    that is required for Peft training&#39;&#39;&#39;</span>
    <span class="n">peft_model</span> <span class="o">=</span> <span class="n">prepare_model_for_kbit_training</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
    <span class="n">peft_model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
    <span class="n">peft_model</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="n">use_cache</span>

    <span class="k">return</span> <span class="n">peft_model</span>

<span class="k">def</span> <span class="nf">setup_trainer</span><span class="p">(</span><span class="n">model</span><span class="p">:</span><span class="n">PeftModel</span><span class="p">,</span> <span class="n">ds</span><span class="p">:</span><span class="nb">dict</span><span class="p">[</span><span class="n">Dataset</span><span class="p">],</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">peft_config</span><span class="p">,</span> <span class="n">custom_args</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">SFTTrainer</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Initialize a HuggingFace SFTTrainer object</span>
<span class="sd">    Args:</span>
<span class="sd">        model: output from prepare_peft_model</span>
<span class="sd">        ds: dict with &quot;train&quot; and &quot;dev&quot; keys, each of which are Dataset objects</span>
<span class="sd">        tokenizer: pretrained tokenizer object</span>
<span class="sd">        peft_config: one of a number of configs that can work with a trainer; see funcs above</span>
<span class="sd">        custom_args:</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">default_args</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;evaluation_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;do_eval&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;optim&quot;</span><span class="p">:</span> <span class="s2">&quot;paged_adamw_32bit&quot;</span><span class="p">,</span>
        <span class="s2">&quot;per_device_train_batch_size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;per_device_eval_batch_size&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
        <span class="s2">&quot;log_level&quot;</span><span class="p">:</span> <span class="s2">&quot;debug&quot;</span><span class="p">,</span>
        <span class="s2">&quot;save_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;steps&quot;</span><span class="p">,</span>
        <span class="s2">&quot;save_steps&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
        <span class="s2">&quot;logging_steps&quot;</span><span class="p">:</span> <span class="mi">25</span><span class="p">,</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="mf">2e-5</span><span class="p">,</span>
        <span class="s2">&quot;group_by_length&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
        <span class="s2">&quot;eval_steps&quot;</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s2">&quot;max_steps&quot;</span><span class="p">:</span> <span class="mi">200</span><span class="p">,</span>
        <span class="s2">&quot;warmup_steps&quot;</span><span class="p">:</span> <span class="mi">30</span><span class="p">,</span>
        <span class="s2">&quot;lr_scheduler_type&quot;</span><span class="p">:</span> <span class="s2">&quot;linear&quot;</span><span class="p">,</span>
        <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span><span class="o">.</span><span class="mi">001</span><span class="p">,</span>
        <span class="s2">&quot;max_grad_norm&quot;</span><span class="p">:</span><span class="o">.</span><span class="mi">3</span><span class="p">,</span>
        <span class="s2">&quot;report_to&quot;</span><span class="p">:</span><span class="s2">&quot;tensorboard&quot;</span><span class="p">}</span>

    <span class="k">if</span> <span class="n">custom_args</span><span class="p">:</span>
        <span class="n">default_args</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">custom_args</span><span class="p">)</span>

    <span class="n">training_arguments</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="o">**</span><span class="n">default_args</span><span class="p">)</span>

    <span class="n">trainer</span> <span class="o">=</span> <span class="n">SFTTrainer</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">dataset_text_field</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">train_dataset</span><span class="o">=</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span>
        <span class="n">eval_dataset</span><span class="o">=</span><span class="n">ds</span><span class="p">[</span><span class="s1">&#39;dev&#39;</span><span class="p">],</span>
        <span class="n">peft_config</span><span class="o">=</span><span class="n">peft_config</span><span class="p">,</span>
        <span class="n">max_seq_length</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
        <span class="n">args</span><span class="o">=</span><span class="n">training_arguments</span><span class="p">,)</span>

    <span class="k">return</span> <span class="n">trainer</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Training-metrics">Training metrics<a class="anchor-link" href="#Training-metrics">&#182;</a></h3><p>Below is an example of the output saved during the training epochs. The loss is the Cross Entropy Loss.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">loss</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mf">2.7495</span><span class="p">,</span>
  <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="mf">16.782007217407227</span><span class="p">,</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">1.7647058823529414e-05</span><span class="p">,</span>
  <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mf">0.0010210749877471001</span><span class="p">,</span>
  <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="mi">50</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mf">2.2949</span><span class="p">,</span>
  <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="mf">12.598627090454102</span><span class="p">,</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">1.1764705882352942e-05</span><span class="p">,</span>
  <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mf">0.0020421499754942002</span><span class="p">,</span>
  <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="mi">100</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mf">2.2661</span><span class="p">,</span>
  <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="mf">14.374794006347656</span><span class="p">,</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">5.882352941176471e-06</span><span class="p">,</span>
  <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mf">0.0030632249632413003</span><span class="p">,</span>
  <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="mi">150</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="mf">2.2124</span><span class="p">,</span>
  <span class="s1">&#39;grad_norm&#39;</span><span class="p">:</span> <span class="mf">13.702934265136719</span><span class="p">,</span>
  <span class="s1">&#39;learning_rate&#39;</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">,</span>
  <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mf">0.0040842999509884004</span><span class="p">,</span>
  <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">},</span>
 <span class="p">{</span><span class="s1">&#39;train_runtime&#39;</span><span class="p">:</span> <span class="mf">1797.4708</span><span class="p">,</span>
  <span class="s1">&#39;train_samples_per_second&#39;</span><span class="p">:</span> <span class="mf">0.89</span><span class="p">,</span>
  <span class="s1">&#39;train_steps_per_second&#39;</span><span class="p">:</span> <span class="mf">0.111</span><span class="p">,</span>
  <span class="s1">&#39;total_flos&#39;</span><span class="p">:</span> <span class="mf">2.588837616554803e+16</span><span class="p">,</span>
  <span class="s1">&#39;train_loss&#39;</span><span class="p">:</span> <span class="mf">2.38071720123291</span><span class="p">,</span>
  <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="mf">0.0040842999509884004</span><span class="p">,</span>
  <span class="s1">&#39;step&#39;</span><span class="p">:</span> <span class="mi">200</span><span class="p">}]</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="In-Context-Learning">In-Context Learning<a class="anchor-link" href="#In-Context-Learning">&#182;</a></h2><p>As mentioned previously, ICL is a method for adapting pre-trained LLMs to specific tasks that leverages the property of LLMs that they are able to perform on previously unseen tasks after seeing some examples of that task.</p>
<p>For Zero-Shot ICL, we didn't give the model any examples of how to perform the task, but simply inserted the prompt "Answer the  quesion truthfully", to clue the model that it is a QA task. In the k-Shot cases, we inserted the prompt "Answer the question truthfully. Follow these examples:" followed by k question-answer pairs in the model-specific chat format.</p>
<p>Below are the utility functions used to insert zero or k-shot prompts plus examples into the proper location in the question, depending on the model.</p>
<p>For all of the following evaluation using the fine-tuned models, we used ICL to the extent that we at least used the basic Zero-Shot prompt.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">process_samples</span><span class="p">(</span><span class="n">sample_data</span><span class="p">:</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Do the actual insertion of the prompt into each example in a sample dataset</span>
<span class="sd">    Args:</span>
<span class="sd">        sample_data: Dataset</span>
<span class="sd">        model_name: one of &quot;google/gemma-7b&quot;, &quot;meta-llama/Llama-2-7b-hf&quot;, &quot;mistralai/Mistral-7B-v0.1&quot;</span>
<span class="sd">        prompt_insert: preprocessed complete prompt</span>
<span class="sd">        tokenizer: pretrained tokenizer</span>
<span class="sd">        &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">model_name</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;google/gemma-7b&quot;</span><span class="p">,</span> <span class="s2">&quot;meta-llama/Llama-2-7b-hf&quot;</span><span class="p">,</span> <span class="s2">&quot;mistralai/Mistral-7B-v0.1&quot;</span><span class="p">]</span>
    <span class="n">model_to_insert_point</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;google/gemma-7b&#39;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
        <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span><span class="p">:</span> <span class="s2">&quot;&lt;s&gt;&quot;</span><span class="p">,</span>
        <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span><span class="p">:</span> <span class="s2">&quot;[INST]&quot;</span><span class="p">}</span>
    
    <span class="n">original_dataset</span><span class="p">,</span> <span class="n">new_tokenizations</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">sample_data</span><span class="p">:</span>
        <span class="n">text</span> <span class="o">=</span> <span class="n">example</span><span class="p">[</span><span class="s1">&#39;questions&#39;</span><span class="p">]</span>
        <span class="n">insertion_point</span> <span class="o">=</span> <span class="n">text</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="n">model_to_insert_point</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="n">model_to_insert_point</span><span class="p">[</span><span class="n">model_name</span><span class="p">])</span>
        <span class="n">new_text</span> <span class="o">=</span> <span class="n">text</span><span class="p">[:</span><span class="n">insertion_point</span><span class="p">]</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">prompt_insert</span> <span class="o">+</span> <span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">text</span><span class="p">[</span><span class="n">insertion_point</span><span class="p">:]</span>
        
        <span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">new_text</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>  
        <span class="n">original_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">new_tokenizations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
    <span class="n">processed_samples</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;prompt_tokenizations&#39;</span><span class="p">:</span> <span class="n">new_tokenizations</span><span class="p">,</span> <span class="s1">&#39;original_dataset&#39;</span><span class="p">:</span> <span class="n">original_dataset</span><span class="p">}</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">processed_samples</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">out</span>

<span class="k">def</span> <span class="nf">preprocess_prompt_icl</span><span class="p">(</span><span class="n">hf_model</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">ds</span><span class="p">:</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">experiment</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">k_shot</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span> <span class="s2">&quot;Answer this question truthfully&quot;</span><span class="p">,</span> 
                          <span class="n">max_k_shot_token_length</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39; Add a prompt or prompt plus examples to a point within each example in a dataset</span>
<span class="sd">    Args:</span>
<span class="sd">        hf_model: one of &quot;google/gemma-7b&quot;, &quot;meta-llama/Llama-2-7b-hf&quot;, &quot;mistralai/Mistral-7B-v0.1&quot;;</span>
<span class="sd">            used to load the model-specific pretrained tokenizer and to determine at which point in the question the</span>
<span class="sd">            prompts should be inserted</span>
<span class="sd">        ds: processed Dataset object</span>
<span class="sd">        experiment: one of &quot;k_shot&quot; or &quot;zero_shot&quot; to determine how to add prompts to the examples in the dataset</span>
<span class="sd">        k_shot: for the &quot;k_shot&quot; case, how many examples to add</span>
<span class="sd">        prompt_insert: the prompt to put before the question or before the examples</span>
<span class="sd">        max_k_shot_token_length: the max number of tokens allowed for the example to be included in k-shot preprocessing</span>
<span class="sd">        sample: how many examples to take from ds</span>
<span class="sd">        &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="n">k_shot</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;k_shot&quot;</span><span class="p">,</span> <span class="s2">&quot;zero_shot&quot;</span><span class="p">]</span>
    <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>

    <span class="n">loaded_tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">hf_model</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

    <span class="k">def</span> <span class="nf">filter_by_token_length</span><span class="p">(</span><span class="n">example</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
        <span class="sd">&#39;&#39;&#39;remove examples from the dataset  that are longer than max_k_shot_token_length&#39;&#39;&#39;</span>
        <span class="n">tokens</span> <span class="o">=</span> <span class="n">loaded_tokenizer</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;text&#39;</span><span class="p">],</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">tokens</span><span class="o">.</span><span class="n">input_ids</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_k_shot_token_length</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Running prompt injection for: </span><span class="si">{experiment}</span><span class="s1">&#39;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">experiment</span> <span class="o">==</span> <span class="s1">&#39;zero_shot&#39;</span><span class="p">:</span>
        <span class="n">prompt_insert</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{prompt_insert}</span><span class="s1">:&#39;</span>
        <span class="n">results</span> <span class="o">=</span> <span class="n">process_samples</span><span class="p">(</span><span class="n">eval_sample</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="p">,</span> <span class="n">loaded_tokenizer</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">experiment</span> <span class="o">==</span> <span class="s1">&#39;k_shot&#39;</span><span class="p">:</span>
        <span class="n">filtered_dataset_for_k_shot</span> <span class="o">=</span>  <span class="n">ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">filter_by_token_length</span><span class="p">)</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">filtered_dataset_for_k_shot</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">k_shot</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;Dataset has less than </span><span class="si">{k_shot}</span><span class="s2"> examples&quot;</span><span class="p">)</span>
        <span class="c1"># Add examples after base prompt</span>
        <span class="n">prompt_insert</span> <span class="o">=</span> <span class="n">f</span><span class="s2">&quot;</span><span class="si">{prompt_insert}</span><span class="s2">. Follow these examples:&quot;</span>
        <span class="k">for</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">filtered_dataset_for_k_shot</span><span class="p">[</span><span class="s1">&#39;questions&#39;</span><span class="p">][:</span><span class="n">k_shot</span><span class="p">],</span> <span class="n">filtered_dataset_for_k_shot</span><span class="p">[</span><span class="s1">&#39;answers&#39;</span><span class="p">][:</span><span class="n">k_shot</span><span class="p">]):</span>
            <span class="n">prompt_insert</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="n">prompt_insert</span> <span class="o">+=</span> <span class="p">(</span><span class="n">q</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span>
            <span class="n">prompt_insert</span> <span class="o">+=</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="n">prompt_insert</span> <span class="o">+=</span> <span class="s1">&#39;Question:&#39;</span>

        <span class="n">results</span> <span class="o">=</span> <span class="n">process_samples</span><span class="p">(</span><span class="n">eval_sample</span><span class="p">,</span> <span class="n">hf_model</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="p">,</span> <span class="n">loaded_tokenizer</span><span class="p">)</span>
    <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">concatenate_datasets</span><span class="p">([</span><span class="n">eval_sample</span><span class="p">,</span> <span class="n">results</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eval_sample</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Inference-and-Evaluation">Inference and Evaluation<a class="anchor-link" href="#Inference-and-Evaluation">&#182;</a></h2><p>For each model, we evaluated each fine-tuned version on the test dataset, which contains samples across the 11 UnifiedQA datasets.</p>
<p>For each sample, the question text, preprocessed to have the model-specific chat tags, was fed to the model and the generated text was collected as the prediction. The answer was then stripped out of that prediction, which was also formatted according to the model-specific chat format, saved, and compared to the ground-truth (human generated) answers to each question.</p>
<p>Below are a few functions used for loading the trained model, predicting using it, and stripping the answers, and saving the predictions for evaluation.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="c1"># HuggingFace packages: </span>
<span class="kn">import</span> <span class="nn">datasets</span>
<span class="kn">from</span> <span class="nn">peft</span> <span class="k">import</span> <span class="n">AutoPeftModelForCausalLM</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="k">import</span> <span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">BitsAndBytesConfig</span>
<span class="n">CONFIG_8BITS</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_8bit</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">load_model</span><span class="p">(</span><span class="n">base_model</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">bnb_config</span><span class="p">:</span><span class="n">BitsAndBytesConfig</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">access_token</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> 
               <span class="n">use_cache</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretraining_tp</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AutoModelForCausalLM</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Load a pretrained HuggingFace model and Tokenizer using a bits and bytes config&#39;&#39;&#39;</span>
    <span class="n">base_model_loaded</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">base_model</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="n">access_token</span><span class="p">,</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">bnb_config</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
    <span class="n">base_model_loaded</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_cache</span> <span class="o">=</span> <span class="n">use_cache</span>
    <span class="n">base_model_loaded</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">pretraining_tp</span> <span class="o">=</span> <span class="n">pretraining_tp</span>

    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">base_model</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>

    <span class="k">return</span> <span class="n">base_model_loaded</span><span class="p">,</span> <span class="n">tokenizer</span>


<span class="k">def</span> <span class="nf">load_model_for_eval</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">local_trained_model_path</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">quant_config</span><span class="o">=</span><span class="n">CONFIG_8BITS</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">AutoModelForCausalLM</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Load a pretrained HuggingFace model and Tokenizer using a bits and bytes config, don&#39;t include settings req&#39;d for training&#39;&#39;&#39;</span>
    <span class="n">peft_model</span> <span class="o">=</span> <span class="n">AutoPeftModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">local_trained_model_path</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">quant_config</span><span class="p">)</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">eos_token</span>
    <span class="n">tokenizer</span><span class="o">.</span><span class="n">padding_side</span> <span class="o">=</span> <span class="s2">&quot;right&quot;</span>
    <span class="k">return</span> <span class="n">peft_model</span><span class="p">,</span> <span class="n">tokenizer</span>


<span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">trained_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">eval_sample</span><span class="p">:</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">prompted</span><span class="p">:</span><span class="nb">bool</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Create a list of predictions using a fine-tuned model on a eval dataset</span>
<span class="sd">    Args:</span>
<span class="sd">        trained_model: fine-tuned model</span>
<span class="sd">        tokenizer: pretrained tokenizer</span>
<span class="sd">        eval_sample: preprocessed data; must have &quot;prompt_tokenizations&quot; column if prompted=True</span>
<span class="sd">        prompted: whether to use the prompt_tokenizations column for question-asking</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">prompted</span><span class="o">==</span><span class="kc">True</span><span class="p">:</span>
        <span class="k">assert</span> <span class="s1">&#39;prompt_tokenizations&#39;</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">eval_sample</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">f</span><span class="s2">&quot;Eval Data needs the following column: &#39;prompt_tokenizations&#39;, but instead has { list(eval_sample.features.keys()) }&quot;</span>
        <span class="n">token_col</span> <span class="o">=</span> <span class="s1">&#39;prompt_tokenizations&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">assert</span> <span class="s1">&#39;input_ids&#39;</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="n">eval_sample</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">f</span><span class="s2">&quot;Eval Data needs the following column: &#39;input_ids&#39;, but instead has { list(eval_sample.features.keys()) }&quot;</span>
        <span class="n">token_col</span> <span class="o">=</span> <span class="s1">&#39;input_ids&#39;</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
      <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;cuda is available&#39;</span><span class="p">)</span>
      <span class="n">eval_sample</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">eval_sample</span><span class="o">.</span><span class="n">set_format</span><span class="p">(</span><span class="s2">&quot;torch&quot;</span><span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">latencies</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># collect how long each prediction takes</span>
    <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">eval_sample</span><span class="p">[</span><span class="n">token_col</span><span class="p">]:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="n">trained_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outp</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span> <span class="c1"># calculate latency</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">latencies</span>


<span class="k">def</span> <span class="nf">strip_output_text</span><span class="p">(</span><span class="n">output</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Post-process prediction text&#39;&#39;&#39;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">output</span> 
    <span class="n">xplicit_answer_idx</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;Answer&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">xplicit_answer_idx</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">xplicit_answer_idx</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Answer&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;google/gemma-7b&#39;</span> <span class="ow">or</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;google/gemma-2b&#39;</span><span class="p">:</span>
            <span class="n">model_start</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">model_start</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">start_idx</span> <span class="o">=</span> <span class="n">model_start</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;model&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:]</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z\s]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">out</span>
    <span class="k">elif</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span><span class="p">:</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;Output:&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Output:&quot;</span><span class="p">)</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">end_idx</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z\s]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\bbinbash\b|\becho\b&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">out</span>
    <span class="k">elif</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span><span class="p">:</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;Output:&quot;</span><span class="p">)</span> <span class="o">+</span> <span class="nb">len</span><span class="p">(</span><span class="s2">&quot;Output:&quot;</span><span class="p">)</span>
            <span class="n">end_idx</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">start_idx</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">end_idx</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">:</span>
                <span class="n">end_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:</span><span class="n">end_idx</span><span class="p">]</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z\s]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;\bbinbash\b|\becho\b&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">,</span> <span class="n">flags</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">IGNORECASE</span><span class="p">)</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">out</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model_name should be one of &#39;google/gemma-7b&#39;, &#39;google/gemma-2b&#39;, &#39;meta-llama/Llama-2-7b-hf&#39;, or &#39;mistralai/Mistral-7B-v0.1&#39;&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">strip_answers</span><span class="p">(</span><span class="n">answer_text</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span> 
    <span class="sd">&#39;&#39;&#39;Post-process ground truth answers from each dataset&#39;&#39;&#39;</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">answer_text</span>
    <span class="k">if</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;google/gemma-7b&#39;</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">strp</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;&lt;start_of_turn&gt;model</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="s1">&#39;&lt;end_of_turn&gt;&#39;</span><span class="p">]:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">strp</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">model_name</span> <span class="o">==</span> <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span><span class="p">:</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">out</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;Output:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^a-zA-Z\s]+&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;\s+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">out</span>


<span class="k">def</span> <span class="nf">add_dataset_name_col</span><span class="p">(</span><span class="n">ds</span><span class="p">:</span><span class="n">Dataset</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Convenience func to add col that indicates which original dataset each prediction </span>
<span class="sd">    and ground truth came from&#39;&#39;&#39;</span>
    <span class="n">original_dataset</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">:</span>
        <span class="n">original_dataset</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">concatenate_datasets</span><span class="p">([</span><span class="n">ds</span><span class="p">,</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span><span class="s1">&#39;original_dataset&#39;</span><span class="p">:</span> <span class="n">original_dataset</span><span class="p">})],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">eval_sample</span>

<span class="k">def</span> <span class="nf">prediction_wrapper</span><span class="p">(</span><span class="n">trained_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> <span class="n">ds</span><span class="p">:</span><span class="n">Dataset</span><span class="p">,</span> 
                       <span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">add_prompt</span><span class="p">:</span><span class="nb">str</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dataset</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Predict using fine-tuned dataset and post-process both predictions and ground truth, creating </span>
<span class="sd">    a new dataset for evaluation</span>
<span class="sd">    Args:</span>
<span class="sd">        trained_model: fine-tuned model</span>
<span class="sd">        tokenizer: pretrained tokenizer</span>
<span class="sd">        ds: processed Dataset object</span>
<span class="sd">        model_name: one of &quot;google/gemma-7b&quot;, &quot;meta-llama/Llama-2-7b-hf&quot;, &quot;mistralai/Mistral-7B-v0.1&quot;</span>
<span class="sd">        add_prompt: prompt to add</span>
<span class="sd">        sample: how many example from eval dataset to predict on</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">add_prompt</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">sample</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">preprocess_prompt_icl</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="s1">&#39;zero_shot&#39;</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="o">=</span><span class="n">add_prompt</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">sample</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">add_prompt</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">sample</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">sample_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">add_dataset_name_col</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">add_prompt</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">sample</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span> <span class="c1"># if sample == 0, use the whole dataset</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">preprocess_prompt_icl</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">experiment</span><span class="o">=</span><span class="s1">&#39;zero_shot&#39;</span><span class="p">,</span> <span class="n">prompt_insert</span><span class="o">=</span><span class="n">add_prompt</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">ds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">add_dataset_name_col</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;eval_sample generated&quot;</span><span class="p">)</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">latencies</span> <span class="o">=</span> <span class="n">predict</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">eval_sample</span><span class="p">,</span> <span class="n">prompted</span><span class="o">=</span><span class="n">add_prompt</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predictions generated&quot;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">strip_output_text</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
    <span class="n">answers_stripped</span> <span class="o">=</span> <span class="p">[</span><span class="n">strip_answers</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">eval_sample</span><span class="p">[</span><span class="s1">&#39;answers&#39;</span><span class="p">]]</span>

    <span class="n">pred_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
        <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">],</span>
        <span class="s1">&#39;ground_truth&#39;</span><span class="p">:</span><span class="n">answers_stripped</span><span class="p">,</span>
        <span class="s1">&#39;original_dataset&#39;</span><span class="p">:</span><span class="n">eval_sample</span><span class="p">[</span><span class="s1">&#39;original_dataset&#39;</span><span class="p">],</span>
        <span class="s1">&#39;latencies&#39;</span><span class="p">:</span> <span class="n">latencies</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">pred_ds</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Below is the process of calling the above functions in the full inference procedure.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">base_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;{os.getcwd()}/temp/Efficient-LLM-Benchmark&#39;</span>
<span class="n">local_models_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{base_path}</span><span class="s1">/Experiments/trained_models&#39;</span>
<span class="n">gcp_paths</span> <span class="o">=</span> <span class="p">[</span>
    <span class="c1"># &#39;gemma_2b_qlora_4bits_norm_nested_outputs/gemma_2b_qlora_4bits_norm_nested_final/&#39;,</span>
    <span class="c1"># &#39;gemma_7b_qlora_4bits_norm_nested_outputs/gemma_7b_qlora_4bits_norm_nested_final&#39;,</span>
    <span class="c1"># &#39;llama2_7b_qlora_4bits_norm_nested_outputs/llama2_7b_qlora_4bits_norm_nested_final&#39;,</span>
    <span class="s1">&#39;mistral_7b_qlora_4bits_norm_nested_outputs/mistral_7b_qlora_4bits_norm_nested_final&#39;</span>
<span class="p">]</span>
<span class="c1"># base_model_name = &quot;google/gemma-2b&quot;</span>
<span class="c1"># base_model_name = &quot;google/gemma-7b&quot;</span>
<span class="c1"># base_model_name = &#39;meta-llama/Llama-2-7b-hf&#39;</span>
<span class="n">base_model_name</span> <span class="o">=</span> <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span>

<span class="n">base_model_test_data_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;google/gemma-2b&quot;</span><span class="p">:</span> <span class="s1">&#39;Gemma_NEW&#39;</span><span class="p">,</span>
    <span class="s2">&quot;google/gemma-7b&quot;</span><span class="p">:</span> <span class="s1">&#39;Gemma_NEW&#39;</span><span class="p">,</span>
    <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span><span class="p">:</span> <span class="s1">&#39;Llama_NEW&#39;</span><span class="p">,</span>
    <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span><span class="p">:</span> <span class="s1">&#39;Mistral_NEW&#39;</span>
<span class="p">}</span>

<span class="n">base_model_local_model_map</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;google/gemma-2b&quot;</span><span class="p">:</span> <span class="s1">&#39;gemma_2b_qlora_4bits_norm_nested_outputs/gemma_2b_qlora_4bits_norm_nested_final/&#39;</span><span class="p">,</span>
    <span class="s2">&quot;google/gemma-7b&quot;</span><span class="p">:</span> <span class="s1">&#39;gemma_7b_qlora_4bits_norm_nested_outputs/gemma_7b_qlora_4bits_norm_nested_final&#39;</span><span class="p">,</span>
    <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span><span class="p">:</span> <span class="s1">&#39;llama2_7b_qlora_4bits_norm_nested_outputs/llama2_7b_qlora_4bits_norm_nested_final&#39;</span><span class="p">,</span>
    <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span><span class="p">:</span> <span class="s1">&#39;mistral_7b_qlora_4bits_norm_nested_outputs/mistral_7b_qlora_4bits_norm_nested_final&#39;</span>
<span class="p">}</span>

<span class="n">gcp_path</span> <span class="o">=</span> <span class="n">base_model_local_model_map</span><span class="p">[</span><span class="n">base_model_name</span><span class="p">]</span>
<span class="n">local_trained_model_path</span> <span class="o">=</span> <span class="n">f</span><span class="s1">&#39;</span><span class="si">{local_models_path}</span><span class="s1">/</span><span class="si">{gcp_path}</span><span class="s1">&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">test_data</span> <span class="o">=</span> <span class="n">load_tokenized_dataset</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span>
    <span class="n">f</span><span class="s2">&quot;</span><span class="si">{base_path}</span><span class="s2">/UnifiedQA Data Curation/tokenized_NEW/</span><span class="si">{base_model_test_data_map[base_model_name]}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="s2">&quot;test.json&quot;</span><span class="p">))</span>
<span class="n">peft_model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_model_for_eval</span><span class="p">(</span><span class="n">base_model_name</span><span class="p">,</span> <span class="n">local_trained_model_path</span><span class="p">)</span>

<span class="c1"># Batched predictions</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">):</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="n">BATCH_SIZE</span><span class="p">))</span> <span class="c1"># create batch</span>
  <span class="n">pred_ds</span> <span class="o">=</span> <span class="n">prediction_wrapper</span><span class="p">(</span>
    <span class="n">peft_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span>
    <span class="n">base_model_name</span><span class="p">,</span> <span class="n">add_prompt</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span> <span class="c1"># no prompt is added </span>
    <span class="n">save_path</span><span class="o">=</span><span class="n">f</span><span class="s1">&#39;</span><span class="si">{base_path}</span><span class="s1">/Experiments/predictions/</span><span class="si">{gcp_path}</span><span class="s1">/predictions_batch_</span><span class="si">{i}</span><span class="s1">.json&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred_ds</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>




<div class="output_text output_subarea ">
<pre>[&#39;mitochondrion confider n the mitochondrion is a doublemembranebound organelle that i&#39;,
 &#39;lt nielsen tanong emphaticaly what is the main conflict in the story emphatical&#39;,
 &#39;the civil war imparare a rispondere n the civil war greate answer greate answe&#39;,
 &#39;dantes inferno n the film is a good example of how a film can b&#39;,
 &#39;he gets an eye transplant tanong emphatics emphatics are words that express strong feelings emphatics are use&#39;,
 &#39;natural laws unwarrantedly the gods are the cause of all evil and the gods are the caus&#39;,
 &#39;it was once underwater unwarrantedly the fossils of sea animals were found in a cave in arkansas thi&#39;,
 &#39;from a daisys leaves into its underground support system emphatics emphatics are words or phrases that draw attention to something emphatics ar&#39;,
 &#39;on the observation deck of the ge building tanong n what does harry tell david and elise about the chairman&#39;,
 &#39;john hull apprehensible sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentito sentit&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">pred_ds</span><span class="p">[</span><span class="s1">&#39;ground_truth&#39;</span><span class="p">][:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>




<div class="output_text output_subarea ">
<pre>[&#39;mitochondrion&#39;,
 &#39;lt nielsen&#39;,
 &#39;the civil war&#39;,
 &#39;dantes inferno&#39;,
 &#39;he gets an eye transplant&#39;,
 &#39;natural laws&#39;,
 &#39;it was once underwater&#39;,
 &#39;from a daisys leaves into its underground support system&#39;,
 &#39;on the observation deck of the ge building&#39;,
 &#39;john hull&#39;]</pre>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Speculative-Decoding">Speculative Decoding<a class="anchor-link" href="#Speculative-Decoding">&#182;</a></h2><p>As mentioned previously, Speculative Decoding is an algorithm that speeds up sampling from LLMs by computing tokens in parallel using several smaller, approximation models that create a number of guesses at prefixes which are then evaluated by the larger model and chosen if they don’t change the target distribution [13]. We implement speculative decoding by using a 2 billion parameter version of the Gemma model, fine-tuned with QLoRA to create speculative prefixes for the 7 billion parameter Gemma to evaluate directly in the inference/text generation stage.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">speculative_decoding</span><span class="p">(</span><span class="n">full_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> 
                         <span class="n">assistant_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">eval_sample</span><span class="p">:</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Create a list of predictions using a fine-tuned smaller model and a larger pre-trained model </span>
<span class="sd">    (that is not finetuned) on a eval dataset</span>
<span class="sd">    Args:</span>
<span class="sd">        full_model: pre-trained model</span>
<span class="sd">        tokenizer: pretrained tokenizer</span>
<span class="sd">        assistant_model: fine-tuned model</span>
<span class="sd">        eval_sample: preprocessed data; must have &quot;prompt_tokenizations&quot; column if prompted=True</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">latencies</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># collect how long each prediction takes</span>

    <span class="k">for</span> <span class="n">inp</span> <span class="ow">in</span> <span class="n">eval_sample</span><span class="p">[</span><span class="s1">&#39;input_ids&#39;</span><span class="p">]:</span>
        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">outp</span> <span class="o">=</span> <span class="n">full_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">assistant_model</span><span class="o">=</span><span class="n">assistant_model</span><span class="p">,</span> <span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">output_scores</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">outp</span><span class="p">,</span> <span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">predictions</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="n">latencies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">end</span> <span class="o">-</span> <span class="n">start</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span><span class="p">,</span> <span class="n">latencies</span>

<span class="k">def</span> <span class="nf">spec_decod_wrapper</span><span class="p">(</span><span class="n">trained_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">:</span><span class="n">AutoTokenizer</span><span class="p">,</span> 
                       <span class="n">assistant_model</span><span class="p">:</span><span class="n">AutoModelForCausalLM</span><span class="p">,</span> <span class="n">ds</span><span class="p">:</span><span class="n">Dataset</span><span class="p">,</span> <span class="n">model_name</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">sample</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">seed</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Predict using speculative decoding approach and post-process both predictions and ground truth, creating </span>
<span class="sd">    a new dataset for evaluation</span>
<span class="sd">    Args:</span>
<span class="sd">        trained_model: pre-trained model</span>
<span class="sd">        tokenizer: pretrained tokenizer</span>
<span class="sd">        assistant_model: fine-tuned model</span>
<span class="sd">        ds: processed Dataset object</span>
<span class="sd">        model_name: one of &quot;google/gemma-7b&quot;, &quot;meta-llama/Llama-2-7b-hf&quot;, &quot;mistralai/Mistral-7B-v0.1&quot;</span>
<span class="sd">        sample: how many example from eval dataset to predict on</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">sample</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">ds</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">sample_data</span> <span class="o">=</span> <span class="n">ds</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">sample</span><span class="p">))</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">add_dataset_name_col</span><span class="p">(</span><span class="n">sample_data</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">eval_sample</span> <span class="o">=</span> <span class="n">add_dataset_name_col</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;eval_sample generated&quot;</span><span class="p">)</span>
    <span class="n">predictions</span><span class="p">,</span> <span class="n">latencies</span> <span class="o">=</span> <span class="n">speculative_decoding</span><span class="p">(</span><span class="n">trained_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">assistant_model</span><span class="p">,</span> <span class="n">eval_sample</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;predictions generated&quot;</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">strip_output_text</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">]</span>
    <span class="n">answers_stripped</span> <span class="o">=</span> <span class="p">[</span><span class="n">strip_answers</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="n">model_name</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">eval_sample</span><span class="p">[</span><span class="s1">&#39;answers&#39;</span><span class="p">]]</span>

    <span class="n">pred_ds</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({</span>
        <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">predictions</span><span class="p">],</span>
        <span class="s1">&#39;ground_truth&#39;</span><span class="p">:</span><span class="n">answers_stripped</span><span class="p">,</span>
        <span class="s1">&#39;original_dataset&#39;</span><span class="p">:</span><span class="n">eval_sample</span><span class="p">[</span><span class="s1">&#39;original_dataset&#39;</span><span class="p">],</span>
        <span class="s1">&#39;latencies&#39;</span><span class="p">:</span> <span class="n">latencies</span><span class="p">})</span>

    <span class="k">return</span> <span class="n">pred_ds</span>


<span class="n">CONFIG_4BITS</span> <span class="o">=</span> <span class="n">BitsAndBytesConfig</span><span class="p">(</span><span class="n">load_in_4bit</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">bnb_4bit_compute_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">)</span> 

<span class="n">large_model</span><span class="p">,</span> <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">load_model</span><span class="p">(</span>
    <span class="n">base_model</span><span class="o">=</span><span class="n">base_model_name</span><span class="p">,</span> <span class="n">bnb_config</span><span class="o">=</span><span class="n">CONFIG_4BITS</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">pretraining_tp</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">assistant_model</span> <span class="o">=</span> <span class="n">AutoPeftModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="n">local_trained_model_path</span><span class="p">,</span> <span class="n">device_map</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">},</span> <span class="n">quantization_config</span><span class="o">=</span><span class="n">CONFIG_4BITS</span><span class="p">)</span>

<span class="c1"># Batched predictions</span>
<span class="n">BATCH_SIZE</span> <span class="o">=</span> <span class="mi">50</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="n">BATCH_SIZE</span><span class="p">):</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
  <span class="n">s</span> <span class="o">=</span> <span class="n">test_data</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="n">BATCH_SIZE</span><span class="p">))</span> <span class="c1"># create batch</span>
  <span class="n">pred_ds</span> <span class="o">=</span> <span class="n">spec_decod_wrapper</span><span class="p">(</span>
    <span class="n">large_model</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">,</span> <span class="n">assistant_model</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span>
    <span class="n">base_model_name</span><span class="p">,</span> <span class="n">sample</span><span class="o">=</span><span class="n">BATCH_SIZE</span><span class="p">,</span><span class="c1"># no prompt is added </span>
    <span class="n">save_path</span><span class="o">=</span><span class="n">f</span><span class="s1">&#39;</span><span class="si">{base_path}</span><span class="s1">/Experiments/predictions/spec_decod/gemma_7b/assistant_qlora_gemma_2b/predictions_batch_</span><span class="si">{i}</span><span class="s1">.json&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Metrics">Metrics<a class="anchor-link" href="#Metrics">&#182;</a></h3><p>The metrics we used to evaluate the success of each method are accuracy, perplexity, and GPU throughput.</p>
<p>Accuracy measures how many correct outputs the model produces [16]. We calculated Jaccard similarity between each answer generated during testing with the ground truth answer. Jaccard similarity is the number of common tokens between the two strings divided by the total length of the longer string [17]. A Jaccard similarity of 1 would indicate a perfect match and thus count as a “correct” output. Because this is a stringent criteria for success in natural language understanding, we also report average Jaccard similarity across the test set for each fine-tuning approach on each model.</p>
<p>GPU Throughput is simply the number of output tokens the model generates per second and is higher for models with higher inference-time efficiency [18]. In order to measure throughput, we recorded the time required for each batch of inference tokens to be produced (latency in seconds) and then divided the number of produced tokens by that latency [19].</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">evaluate</span>
<span class="n">rouge</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;rouge&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">compute_accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">:</span><span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="n">num_correct</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">score</span> <span class="ow">in</span> <span class="n">scores</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">score</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">num_correct</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="p">((</span><span class="n">num_correct</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">accuracy</span>

<span class="c1"># Rouge is a similarity measure based on longest common subsequence ; used for summarization tasks</span>
<span class="k">def</span> <span class="nf">compute_rouge</span><span class="p">(</span><span class="n">predictions</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">:</span><span class="nb">list</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;computing similarity for summarization&#39;</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">rouge</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">ground_truth</span><span class="p">,</span> <span class="n">use_aggregator</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span><span class="p">[</span><span class="s1">&#39;rougeL&#39;</span><span class="p">]</span> <span class="c1"># longest common subsequence-based ROUGE</span>

<span class="k">def</span> <span class="nf">jaccard</span><span class="p">(</span><span class="n">str1</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">str2</span><span class="p">:</span><span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&#39;&#39;&#39;Compute jaccard between two strings:  Numb common token between two strings&#39;&#39;&#39;</span>
    <span class="k">if</span> <span class="n">str1</span> <span class="o">==</span> <span class="n">str2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">1.0</span>
    <span class="k">if</span> <span class="s2">&quot; &quot;</span> <span class="ow">in</span> <span class="n">str1</span> <span class="ow">or</span> <span class="s2">&quot; &quot;</span> <span class="ow">in</span> <span class="n">str2</span><span class="p">:</span>
        <span class="n">str1_split</span> <span class="o">=</span> <span class="n">str1</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">str2_split</span> <span class="o">=</span> <span class="n">str2</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)</span>
        <span class="n">overlap</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">str1_split</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">str2_split</span><span class="p">))</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="n">overlap</span><span class="p">)</span> <span class="o">/</span> <span class="nb">max</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">str1_split</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">str2_split</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mf">0.0</span>
    
<span class="k">def</span> <span class="nf">compute_similarity</span><span class="p">(</span><span class="n">predictions</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">:</span><span class="nb">list</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Apply jaccard similarity for multiple choice questions to get evaluation scores&#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;computing similarity for multiple choice&#39;</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">p</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">):</span>
      <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">jaccard</span><span class="p">(</span><span class="n">p</span><span class="p">,</span><span class="n">l</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">compute_scores</span><span class="p">(</span><span class="n">original_dataset</span><span class="p">:</span><span class="nb">str</span><span class="p">,</span> <span class="n">predictions</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">:</span><span class="nb">list</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Compute scores across a eval dataset</span>
<span class="sd">    Args:</span>
<span class="sd">        original_dataset: one of the keys in the ds_metric_map</span>
<span class="sd">        precitions: list of predictions</span>
<span class="sd">        ground_truth: list of correct answers    </span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">ds_metric_map</span> <span class="o">=</span> <span class="p">{</span> <span class="c1"># which original dataset has which type of question -&gt; determines which metric to use</span>
        <span class="s1">&#39;ai2_science_elementary&#39;</span><span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">,</span> <span class="c1"># mc is multiple choice </span>
        <span class="s1">&#39;ai2_science_middle&#39;</span><span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;arc_easy&#39;</span><span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;arc_hard&#39;</span><span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;narrativeqa&#39;</span><span class="p">:</span> <span class="s1">&#39;rouge&#39;</span><span class="p">,</span>
        <span class="s1">&#39;openbookqa&#39;</span> <span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">,</span>
        <span class="s1">&#39;race_string&#39;</span><span class="p">:</span> <span class="s1">&#39;mc&#39;</span><span class="p">}</span>
    <span class="k">assert</span> <span class="n">original_dataset</span> <span class="ow">in</span> <span class="n">ds_metric_map</span><span class="p">,</span> <span class="n">f</span><span class="s2">&quot;Please define a metric mapping for dataset </span><span class="si">{original_dataset}</span><span class="s2">&quot;</span>
    <span class="n">metric</span> <span class="o">=</span> <span class="n">ds_metric_map</span><span class="p">[</span><span class="n">original_dataset</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;rouge&#39;</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">compute_rouge</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">metric</span> <span class="o">==</span> <span class="s1">&#39;mc&#39;</span><span class="p">:</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">compute_similarity</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">scores</span>

<span class="k">def</span> <span class="nf">throughput</span><span class="p">(</span><span class="n">latencies</span><span class="p">:</span><span class="nb">list</span><span class="p">,</span> <span class="n">predictions</span><span class="p">:</span><span class="nb">list</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Compute throughput as average of the latency of each token was generated &#39;&#39;&#39;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;computing throughput&#39;</span><span class="p">)</span>
    <span class="n">through_put</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">l</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">latencies</span><span class="p">,</span> <span class="n">predictions</span><span class="p">):</span>
        <span class="n">output_tokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">p</span><span class="p">)</span>
        <span class="n">through_put</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">output_tokens</span> <span class="o">/</span> <span class="n">l</span><span class="p">)</span> <span class="c1"># how long did each token take to be generated?</span>

    <span class="n">avg_through_put</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">through_put</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">through_put</span><span class="p">)</span> <span class="c1"># </span>
    <span class="k">return</span> <span class="n">avg_through_put</span>

<span class="k">def</span> <span class="nf">evaluate_predictions</span><span class="p">(</span><span class="n">pred_ds</span><span class="p">:</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;Wrapper func to compute accuracy, throughput, and score for a set of predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        pred_ds: should contain [&#39;predictions&#39;, &#39;ground_truth&#39;, &#39;original_dataset&#39;, &#39;latencies&#39;] keys</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="k">assert</span> <span class="nb">list</span><span class="p">(</span><span class="n">pred_ds</span><span class="o">.</span><span class="n">features</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span> <span class="o">==</span> <span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">,</span> <span class="s1">&#39;ground_truth&#39;</span><span class="p">,</span> <span class="s1">&#39;original_dataset&#39;</span><span class="p">,</span> <span class="s1">&#39;latencies&#39;</span><span class="p">],</span> <span class="n">f</span><span class="s2">&quot;Prediction dataset must have [&#39;predictions&#39;, &#39;ground_truth&#39;, &#39;original_dataset&#39;] in columns, currently has {list(pred_ds.features.keys()) }.&quot;</span>
    <span class="c1"># Concatenate evaluations per dataset because each one could have something slightly different happening</span>
    <span class="c1"># depending on what type of question/answer is in that dataset (namely summarization vs multiple choice)</span>
    <span class="n">original_datasets</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">pred_ds</span><span class="p">[</span><span class="s1">&#39;original_dataset&#39;</span><span class="p">])</span>
    <span class="n">filt</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">ds</span> <span class="ow">in</span> <span class="n">original_datasets</span><span class="p">:</span>
        <span class="n">filt</span><span class="p">[</span><span class="n">ds</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_ds</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">ex</span><span class="p">:</span> <span class="n">ex</span><span class="p">[</span><span class="s1">&#39;original_dataset&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="n">ds</span><span class="p">)</span>

    <span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ds</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">filt</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">scores</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">compute_scores</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;ground_truth&#39;</span><span class="p">]))</span>

    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">compute_accuracy</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

    <span class="n">tp</span> <span class="o">=</span> <span class="n">throughput</span><span class="p">(</span><span class="n">pred_ds</span><span class="p">[</span><span class="s1">&#39;latencies&#39;</span><span class="p">],</span> <span class="n">pred_ds</span><span class="p">[</span><span class="s1">&#39;predictions&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">scores</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">tp</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Perplexity">Perplexity<a class="anchor-link" href="#Perplexity">&#182;</a></h3><p>Perplexity captures the degree of uncertainty of the model when seeing new data, and the lower the perplexity the better [20]. Mathematically, it is the exponentiated average negative log-likelihood of a sequence [21]. The log-likelihood of a sequence is the sum of the likelihoods of each item in the sequence conditioned on the previous items in the sequence. We calculated perplexity by exponentiating the training loss (cross entropy loss) at the end of training for each fine-tuning method.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1"># Load the training loss metrics</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;{os.getcwd()}/content/Projects/supplemental/efficient_ft_llm/metrics/training_metrics.json&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
  <span class="n">data</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s2">&quot;{os.getcwd()}/content/Projects/supplemental/efficient_ft_llm/metrics/peft_metrics.json&quot;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fp</span><span class="p">:</span>
  <span class="n">metrics</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">fp</span><span class="p">)</span>

<span class="c1"># Load pre-computed eval and training metrics and add training loss and perplexity to </span>
<span class="c1"># eval metrics</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">i</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">if</span> <span class="s1">&#39;gemma&#39;</span> <span class="ow">in</span> <span class="n">method</span><span class="p">:</span>
      <span class="k">if</span> <span class="s1">&#39;7b&#39;</span> <span class="ow">in</span> <span class="n">method</span><span class="p">:</span>
          <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;google/gemma-7b&#39;</span>
      <span class="k">elif</span> <span class="s1">&#39;2b&#39;</span> <span class="ow">in</span> <span class="n">method</span><span class="p">:</span>
          <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;google/gemma-2b&#39;</span>
    <span class="k">elif</span> <span class="s1">&#39;llama2&#39;</span> <span class="ow">in</span> <span class="n">method</span><span class="p">:</span>
      <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;meta-llama/Llama-2-7b-hf&#39;</span>
    <span class="k">elif</span> <span class="s1">&#39;mistral&#39;</span> <span class="ow">in</span> <span class="n">method</span><span class="p">:</span>
      <span class="n">model</span> <span class="o">=</span> <span class="s1">&#39;mistralai/Mistral-7B-v0.1&#39;</span>
    <span class="k">if</span> <span class="n">method</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">]:</span>
      <span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">][</span><span class="n">method</span><span class="p">]</span><span class="o">=</span><span class="p">{}</span>
    <span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">][</span><span class="n">method</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>
    <span class="n">metrics</span><span class="p">[</span><span class="n">model</span><span class="p">][</span><span class="n">method</span><span class="p">][</span><span class="s1">&#39;perplexity&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">j</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">])</span> <span class="c1"># exponentiate loss to get perplexity</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Metrics-Plotting">Metrics Plotting<a class="anchor-link" href="#Metrics-Plotting">&#182;</a></h2><p>Accross each model and method, each metric is plotted below.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">for_plot</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="o">.</span><span class="n">from_dict</span><span class="p">({(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">):</span> <span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> 
                           <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">metrics</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> 
                           <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">metrics</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()},</span>
                       <span class="n">orient</span><span class="o">=</span><span class="s1">&#39;index&#39;</span><span class="p">)</span>
<span class="n">for_plot</span> <span class="o">=</span> <span class="n">for_plot</span><span class="o">.</span><span class="n">reset_index</span><span class="p">()</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;level_0&#39;</span><span class="p">:</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;level_1&#39;</span><span class="p">:</span><span class="s1">&#39;method&#39;</span><span class="p">})</span>
<span class="n">for_plot</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">for_plot</span><span class="p">[</span><span class="s1">&#39;method&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="s1">&#39;_&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;_&#39;</span><span class="p">)[</span><span class="mi">2</span><span class="p">:</span><span class="mi">4</span><span class="p">]))</span>
<span class="n">for_plot</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">for_plot</span><span class="p">[</span><span class="s1">&#39;model&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;/&#39;</span><span class="p">)[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">for_plot</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>



<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>model</th>
      <th>method</th>
      <th>avg_score</th>
      <th>accuracy</th>
      <th>throughput</th>
      <th>loss</th>
      <th>perplexity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>gemma-2b</td>
      <td>qlora_4bits</td>
      <td>0.187840</td>
      <td>0.000000</td>
      <td>169.625242</td>
      <td>3.2044</td>
      <td>2.464071e+01</td>
    </tr>
    <tr>
      <th>1</th>
      <td>gemma-2b</td>
      <td>adalora_4bits</td>
      <td>0.213332</td>
      <td>0.000000</td>
      <td>135.017510</td>
      <td>6.4589</td>
      <td>6.383585e+02</td>
    </tr>
    <tr>
      <th>2</th>
      <td>gemma-2b</td>
      <td>ia3_4bits</td>
      <td>0.212516</td>
      <td>0.000000</td>
      <td>180.270467</td>
      <td>3.3529</td>
      <td>2.858551e+01</td>
    </tr>
    <tr>
      <th>3</th>
      <td>gemma-2b</td>
      <td>prompt_tuning</td>
      <td>0.044905</td>
      <td>0.000000</td>
      <td>190.524900</td>
      <td>3.5746</td>
      <td>3.568035e+01</td>
    </tr>
    <tr>
      <th>4</th>
      <td>gemma-7b</td>
      <td>qlora_4bits</td>
      <td>0.505994</td>
      <td>0.137143</td>
      <td>59.367753</td>
      <td>2.7495</td>
      <td>1.563481e+01</td>
    </tr>
    <tr>
      <th>5</th>
      <td>gemma-7b</td>
      <td>prompt_tuning</td>
      <td>0.013714</td>
      <td>0.013714</td>
      <td>0.000000</td>
      <td>19.3197</td>
      <td>2.457192e+08</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Llama-2-7b-hf</td>
      <td>adalora_4bits</td>
      <td>0.597275</td>
      <td>0.417143</td>
      <td>39.833156</td>
      <td>4.3354</td>
      <td>7.635549e+01</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Llama-2-7b-hf</td>
      <td>qlora_4bits</td>
      <td>0.809848</td>
      <td>0.724286</td>
      <td>30.847709</td>
      <td>2.1260</td>
      <td>8.381275e+00</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Llama-2-7b-hf</td>
      <td>ia3_4bits</td>
      <td>0.592964</td>
      <td>0.414571</td>
      <td>50.927902</td>
      <td>2.2229</td>
      <td>9.234071e+00</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Llama-2-7b-hf</td>
      <td>prompt_tuning</td>
      <td>0.011536</td>
      <td>0.003429</td>
      <td>33.725431</td>
      <td>2.2545</td>
      <td>9.530527e+00</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Mistral-7B-v0.1</td>
      <td>adalora_4bits</td>
      <td>0.024165</td>
      <td>0.000000</td>
      <td>1582.300904</td>
      <td>4.9028</td>
      <td>1.346663e+02</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Mistral-7B-v0.1</td>
      <td>qlora_4bits</td>
      <td>0.024165</td>
      <td>0.000000</td>
      <td>2702.280640</td>
      <td>2.1073</td>
      <td>8.226001e+00</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Mistral-7B-v0.1</td>
      <td>ia3_4bits</td>
      <td>0.024165</td>
      <td>0.000000</td>
      <td>1936.053577</td>
      <td>2.3201</td>
      <td>1.017669e+01</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Mistral-7B-v0.1</td>
      <td>prompt_tuning</td>
      <td>0.049205</td>
      <td>0.000000</td>
      <td>114.558090</td>
      <td>2.4132</td>
      <td>1.116965e+01</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Llama-2-7b-hf</td>
      <td>qlora_4bits</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1258</td>
      <td>8.379598e+00</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Mistral-7B-v0.1</td>
      <td>qlora_4bits</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1065</td>
      <td>8.219423e+00</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">
        In&nbsp;[]:
</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;avg_score&#39;</span><span class="p">,</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">,</span> <span class="s1">&#39;throughput&#39;</span><span class="p">]:</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">for_plot</span><span class="p">[[</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">i</span><span class="p">]]</span><span class="o">.</span><span class="n">pivot_table</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="s1">&#39;method&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">values</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="n">plot</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">rot</span><span class="o">=</span><span class="mi">45</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

<div class="output_area">

    
    <div class="prompt output_prompt">
        Out[]:
    </div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="References">References<a class="anchor-link" href="#References">&#182;</a></h1><ol>
<li>Z. Wan et al., “Efficient Large Language Models: A Survey,” arXiv (Cornell University), Dec. 2023. <a href="https://arxiv.org/abs/2312.03863">https://arxiv.org/abs/2312.03863</a>.</li>
<li>L. Xu, H. Xie, S.-Z. J. Qin, X. Tao, and F. L. Wang, “Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment,” arXiv.org, Dec. 19, 2023. <a href="https://arxiv.org/abs/2312.12148">https://arxiv.org/abs/2312.12148</a>.</li>
<li>Z. Liu et al., “Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time,” arXiv.org, Oct. 26, 2023. <a href="https://arxiv.org/abs/2310.17157">https://arxiv.org/abs/2310.17157</a></li>
<li>D. Khashabi et al., “UnifiedQA: Crossing Format Boundaries With a Single QA System,” arXiv.org, Oct. 06, 2020. <a href="https://arxiv.org/abs/2005.00700">https://arxiv.org/abs/2005.00700</a>.</li>
<li><a href="https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder">https://magazine.sebastianraschka.com/p/understanding-encoder-and-decoder</a></li>
<li>E.J. Hu, Y. Shen, P. Wallis, Z. Allen-Zhu, Y. Li, S. Wang, L. Wang, and W. Chen, “LoRA: Low-rank adaptation of large language models,” in Proc. Int. Conf. Learn. Representations, 2022. <a href="https://arxiv.org/abs/2106.09685">https://arxiv.org/abs/2106.09685</a>.</li>
<li>Q. Zhang et al., “Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning,” arXiv.org, Mar. 18, 2023. <a href="https://arxiv.org/abs/2303.10512">https://arxiv.org/abs/2303.10512</a></li>
<li>L. Xu, H. Xie, S.-Z. J. Qin, X. Tao, and F. L. Wang, “Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment,” arXiv.org, Dec. 19, 2023. <a href="https://arxiv.org/abs/2312.12148">https://arxiv.org/abs/2312.12148</a>.</li>
<li>H. Liu, D. Tam, M. Mohammed, J. Mohta, T. Huang, M. Bansal, and C. Raffel, “Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning,” in Proc. Adv. Neural Inf. Process. Syst., 2022.  <a href="https://arxiv.org/abs/2205.05638">https://arxiv.org/abs/2205.05638</a>.</li>
<li>X. Liu, Y. Zheng, Z. Du, M. Ding, Y. Qian, Z. Yang, and J. Tang, “GPT Understands, Too,” arXiv preprint 2021. <a href="https://arxiv.org/abs/2103.10385">https://arxiv.org/abs/2103.10385</a>. </li>
<li>Y. Leviathan, M. Kalman, and Y. Matias, “Fast Inference from Transformers via Speculative Decoding,” arXiv.org, May 18, 2023. <a href="https://arxiv.org/abs/2211.17192">https://arxiv.org/abs/2211.17192</a></li>
<li><a href="https://lambdalabs.com/blog/fine-tuning-metas-llama-2-on-lambda-gpu-cloud">https://lambdalabs.com/blog/fine-tuning-metas-llama-2-on-lambda-gpu-cloud</a></li>
<li>Q. Zhang et al., “Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning,” arXiv.org, Mar. 18, 2023. <a href="https://arxiv.org/abs/2303.10512">https://arxiv.org/abs/2303.10512</a></li>
<li><a href="https://huggingface.co/docs/peft/developer_guides/quantization">https://huggingface.co/docs/peft/developer_guides/quantization</a></li>
<li><a href="https://huggingface.co/docs/peft/v0.10.0/en/package_reference/ia3#peft.IA3Config">https://huggingface.co/docs/peft/v0.10.0/en/package_reference/ia3#peft.IA3Config</a></li>
<li><a href="https://huggingface.co/spaces/evaluate-metric/accuracy">https://huggingface.co/spaces/evaluate-metric/accuracy</a></li>
<li><a href="https://medium.com/@mayurdhvajsinhjadeja/jaccard-similarity-34e2c15fb524">https://medium.com/@mayurdhvajsinhjadeja/jaccard-similarity-34e2c15fb524</a></li>
<li><a href="https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices">https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices</a></li>
<li><a href="https://towardsdatascience.com/deploying-large-language-models-vllm-and-quantizationstep-by-step-guide-on-how-to-accelerate-becfe17396a2">https://towardsdatascience.com/deploying-large-language-models-vllm-and-quantizationstep-by-step-guide-on-how-to-accelerate-becfe17396a2</a></li>
<li><a href="https://medium.com/nlplanet/two-minutes-nlp-perplexity-explained-with-simple-probabilities-6cdc46884584">https://medium.com/nlplanet/two-minutes-nlp-perplexity-explained-with-simple-probabilities-6cdc46884584</a></li>
<li><a href="https://huggingface.co/spaces/evaluate-metric/accuracy">https://huggingface.co/spaces/evaluate-metric/accuracy</a></li>
</ol>

</div>
</div>
</div>
 


<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>

                <h4> <a style="border-bottom: 1px solid #f26a3d;" href="/projects/efficient-ft-llm">Return to the top</a><i class="ic ic-arrow-right"></i></h4><br><br>
            </section>

            <div class="clear"></div>


                <div class="clear"></div>

                <aside class="post-author">


                        <figure class="post-author-avatar">
                            <img src="/images/avatar2.jpeg" alt="Micaela McCall" />
                        </figure>
                    <div class="post-author-bio">
                        <h4 class="post-author-name"><a href="/">Micaela McCall</a></h4>
                            <p class="post-author-about">data scientist, neuroscience enthusiast, <br> DIY skill-builder, nature documentary afficionado</p>
                        <!--                             <span class="post-author-location"><i class="ic ic-location"></i> Washington D.C.</span>
 -->

                        <!-- Social linkes in alphabet order. -->
                        <!--                             <span class="post-author-github"><a target="_blank" href="https://github.com/micaelamccall"><i class="ic ic-link"></i> GitHub</a></span>
                        <span class="post-author-github"><a target="_blank" href="mailto:micaela.v.mccall@gmail.com"><i class="ic ic-posts"></i> Email</a></span>
                            <span class="post-author-linkedin"><a target="_blank" href="https://www.linkedin.com/in/https://www.linkedin.com/in/micaela-mccall/"><i class="ic ic-link"></i> LinkedIn</a></span>
 -->
                    </div>
                    <h5 style="padding-left: 25%">
                                <a href="https://github.com/micaelamccall">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                                <a href="https://www.linkedin.com/in/micaela-mccall/">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                                <a href="mailto:micaela.v.mccall@gmail.com">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                                <a href="tel:5054006344">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-phone fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                    </h5>
                    <div class="clear"></div>
                </aside>
                </section>


                <aside class="post-nav">
                    <div class="clear"></div>
                </aside>

            </div>
        </article>
    </main>
      <!-- TODO : Body class -->
    <div id="body-class" style="display: none;" class=""></div>

    <footer id="footer">
      <div class="inner">
        <section class="credits">


          <span class="credits-theme">© 2019 Micaela McCall</span>
          <span class="credits-software">Published with <a href="https://github.com/arulrajnet/attila" rel="nofollow">Attila for Pelican</a></span>
        </section>
      </div>
    </footer>
  </section>

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script type="text/javascript" src="/theme/js/script.js"></script>

</body>
</html>